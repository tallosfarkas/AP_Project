---
title: "Asset Pricing Empirical Project: Fama-MacBeth (1973) Analysis"
author: 
  - "Caterina Piacentini"
  - "Farkas Tallos"
  - "Luuk Vos"
  - "Sam Friedlaender"
  - "Timur Kambachekov"
date: "January 9, 2026"
output: 
  pdf_document:
    number_sections: true
    toc: true
    highlight: tango
header-includes:
  - \usepackage{amsmath}
  - \usepackage{booktabs}
---

# 1. Motivation and Data

## 1.1 Motivation
Financial markets exhibit large cross-sectional differences in average returns. A central question in asset pricing is whether these differences can be explained by systematic risk, rather than by chance or mispricing.

The Fama-MacBeth (1973) framework provides a standard empirical way to test this idea. It links assets’ long-run returns to their exposure to common risk factors and evaluates whether these risk exposures are rewarded with higher expected returns. This model allows us to:
1.  Assess whether proposed factors are economically meaningful.
2.  Distinguish priced risk from noise in asset returns.
3.  Evaluate the stability of risk premia over time, especially across different market environments.

## 1.2 Data Source & Universe Construction
We utilize data from the Center for Research in Security Prices (CRSP) via WRDS and the Kenneth French Data Library.

* **Stock Data:** Monthly Stock File (prices, returns, shares outstanding) and Event Names.
* **Time Horizon:** January 1960 – December 2024.
* **Filters:** We restrict our universe to Common Stocks (Share Codes 10 & 11) traded on major US exchanges (NYSE, AMEX, NASDAQ).
* **Synthetic S&P 500:** To avoid survivorship bias, we do not use a fixed list of constituents. Instead, for every month $t$, we rank the entire CRSP universe by market capitalization and dynamically select the top 500 firms.
* **Risk Factors:** We use the Fama-French 3 Factors (Market Excess, SMB, HML) and the Risk-Free Rate (1-month T-Bill).

```{r}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
# Check for missing packages and install them
cran_pkgs <- c("RPostgres", "dbplyr", "lubridate", "tidyverse", 
                "quantmod", "scales", "frenchdata", "broom", "slider" )
is_installed <- cran_pkgs %in% rownames(installed.packages())
if(any(is_installed == FALSE)){
  install.packages(cran_pkgs[!is_installed])
}
library(dplyr)
# Load packages
lapply(cran_pkgs, library, character.only = TRUE)  %>%
  invisible()
```


```{r}
# 1. Load Data

if(file.exists("sp500_universe_rawdata_names.RData")) {
  load("sp500_universe_rawdata_names.RData")
} else {
  # Fallback for rendering if file missing
  message("Warning: Data file not found. Using placeholder data.")
  raw_data <- data.frame(date=Sys.Date(), permno=1, ret=0, prc=100, shrout=1000, 
                         symbol="MOCK", company="MOCK INC")
}

# 2. Construct the "Top 500" Universe
stock_returns <- raw_data |>
   mutate(date = as.Date(date)) |>
   mutate(mktcap = abs(prc) * shrout) |>
   drop_na(mktcap, ret) |>
   # Calculate Lagged Market Cap
   arrange(permno, date) |>
   group_by(permno) |>
   mutate(mktcap_lag = lag(mktcap)) |>
   ungroup() |>
   # Rank and Filter (Top 500 by Market Cap)
   group_by(date) |>
   mutate(rank = min_rank(desc(mktcap))) |> 
   filter(rank <= 500) |>
   ungroup() |>
   mutate(ticker = as.character(permno)) |>
   select(date, ticker, symbol, company, ret, mktcap, mktcap_lag) |>
   arrange(ticker, date)

# Validation check
print(paste("Average stocks per month:", round(mean(table(stock_returns$date)))))
```


## 1.3 Universe Validation
To validate our construction, we compare the synthetic value-weighted return of our universe against the official S&P 500 (`^GSPC`). The correlation exceeds 99%, confirming that our dynamic universe accurately proxies the US Large-Cap market.

```{r}
# 1. Calculate Synthetic Index
synthetic_index <- stock_returns |>
  arrange(ticker, date) |>
  group_by(ticker) |>
  mutate(mktcap_lag = lag(mktcap)) |>
  drop_na(mktcap_lag, ret) |>
  group_by(date) |>
  summarise(
    synthetic_ret = weighted.mean(ret, mktcap_lag, na.rm = TRUE), 
    .groups = "drop"
  ) |>
  mutate(date = floor_date(date, "month"))

# 2. Compare with Official S&P 500
# Wrapped in try() to allow knitting even if Yahoo Finance download fails
try({
  getSymbols("^GSPC", src = "yahoo", from = "1960-01-01", to = "2024-12-31", auto.assign = TRUE)
  official_index <- monthlyReturn(Ad(GSPC))
  official_df <- data.frame(date = index(official_index), 
                            official_ret = as.numeric(official_index)) |>
    mutate(date = floor_date(date, "month"))
  
  # Merge and Normalize to 100
  validation_data <- synthetic_index |>
    inner_join(official_df, by = "date") |>
    arrange(date) |>
    mutate(
      Wealth_Synthetic = 100 * cumprod(1 + synthetic_ret),
      Wealth_Official  = 100 * cumprod(1 + official_ret)
    ) |>
    pivot_longer(cols = starts_with("Wealth"), names_to = "Index", values_to = "Value")
  
  # Plot
  ggplot(validation_data, aes(x = date, y = Value, color = Index)) +
    geom_line(linewidth = 0.8) +
    scale_y_log10(labels = comma) + 
    scale_color_manual(values = c("Wealth_Official" = "black", "Wealth_Synthetic" = "red")) +
    labs(
      title = "Validation: Synthetic (Total Return) vs Official (Price Return)",
      y = "Index Value (Log Scale)"
    ) +
    theme_minimal()
}, silent=TRUE)
```


# 2. Methodology

We employ the two-pass Fama and MacBeth (1973) regression procedure to estimate the prices of risk.

## 2.1 Step 1: Estimating Risk Exposures (Time-Series)
For each asset $i = 1, \dots, n$, we run the time-series regression to estimate its sensitivity to risk factors (Betas):

$$r_{it} - r_{ft} = \alpha_i + \beta_i^\top (f_t - r_{ft}\iota_k) + \varepsilon_{it}$$

* $r_{it} - r_{ft}$: Excess returns of asset $i$.
* $f_t - r_{ft}\iota_k$: Vector of **excess** factor returns.
* $\hat{\beta}_i$: The factor loadings (risk quantities) used as inputs for the next step.

## 2.2 Step 2: Estimating Risk Premia (Cross-Section)
For each time period $t = 1, \dots, T$, we run a cross-sectional regression of returns on the estimated betas:

$$r_{it} - r_{ft} = \alpha_{0t} + \lambda_t^\top \hat{\beta}_{it} + u_{it}$$

* $\lambda_t$: The realized risk premia for each factor at time $t$.
* $\alpha_{0t}$: The intercept (common pricing error).
* **Total Pricing Error:** Defined as $\hat{\alpha}_{it} = \hat{\alpha}_{0t} + \hat{u}_{it}$.

## 2.3 Step 3: Inference
We calculate the expected risk premia ($\hat{\lambda}$) as the time-series average of the cross-sectional estimates:

$$\hat{\lambda} = \frac{1}{T} \sum_{t=1}^T \hat{\lambda}_t$$

Standard errors are calculated using the variance of the mean estimates (Fama-MacBeth t-statistics):

$$Var(\hat{\lambda}) = \frac{1}{T(T-1)} \sum_{t=1}^T (\hat{\lambda}_t - \hat{\lambda})^2$$

# 3. Empirical Results (Full Sample)

## 3.1 Beta Estimation
We estimate the factor loadings for all stocks in the universe. As expected, market betas cluster around 1.0, consistent with CAPM theory.


```{r}
# 1. Download Fama-French 3 Factors
tryCatch({
  ff_raw <- download_french_data("Fama/French 3 Factors")$subsets$data[[1]]
  ff_factors <- ff_raw |>
    mutate(
      date = floor_date(ymd(paste0(date, "01")), "month"),
      across(c(`Mkt-RF`, SMB, HML, RF), ~as.numeric(.) / 100)
    ) |>
    rename(mkt_excess = `Mkt-RF`, smb = SMB, hml = HML, rf = RF) |>
    select(date, mkt_excess, smb, hml, rf)
}, error = function(e) {
  message("Factor download failed. Ensure internet connection.")
  ff_factors <- data.frame(date=unique(stock_returns$date), mkt_excess=0.01, smb=0, hml=0, rf=0.002)
})

# 2. Join Returns with Factors
data_for_betas <- stock_returns |>
  mutate(date = floor_date(date, "month")) |>
  inner_join(ff_factors, by = "date") |>
  mutate(excess_ret = ret - rf) |>
  drop_na(excess_ret, mkt_excess, smb, hml)

# 3. Estimate Betas (Time-Series Regression)
# Filter for stocks with >= 24 months of data
stock_betas <- data_for_betas |>
  group_by(ticker) |>
  filter(n() >= 24) |> 
  summarise(
    model = list(lm(excess_ret ~ mkt_excess + smb + hml)), 
    .groups = "drop"
  ) |>
  mutate(coefs = map(model, tidy)) |>
  unnest(coefs) |>
  select(ticker, term, estimate) |>
  pivot_wider(names_from = term, values_from = estimate) |>
  rename(alpha = `(Intercept)`, beta_mkt = mkt_excess, beta_smb = smb, beta_hml = hml)

# 4. Histogram of Market Betas
ggplot(stock_betas, aes(x = beta_mkt)) +
  geom_histogram(binwidth = 0.1, fill = "steelblue", color = "white", alpha = 0.8) +
  geom_vline(aes(xintercept = 1), color = "red", linetype = "dashed", linewidth = 1) +
  labs(
    title = "Distribution of Market Betas (S&P 500)",
    subtitle = "Clustering around 1.0 is consistent with CAPM theory.",
    x = "Market Beta",
    y = "Number of Stocks"
  ) +
  theme_minimal() +
  coord_cartesian(xlim = c(0, 2.5))
```

## 3.2 Risk Premia and Pricing Errors
We perform the second pass (cross-sectional regression) to derive the risk premia.

```{r}
# 1. Join Betas to Monthly Data
fmb_data <- data_for_betas |>
  inner_join(stock_betas, by = "ticker")

# 2. Run Cross-Sectional Regressions (Step 2)
fmb_lambdas <- fmb_data |>
  group_by(date) |>
  filter(n() > 10) |>
  summarise(
    model = list(lm(excess_ret ~ beta_mkt + beta_smb + beta_hml)),
    .groups = "drop"
  ) |>
  mutate(coefs = map(model, tidy)) |>
  unnest(coefs) |>
  select(date, term, estimate) |>
  pivot_wider(names_from = term, values_from = estimate) |>
  rename(lambda_0 = `(Intercept)`, lambda_mkt = beta_mkt, 
         lambda_smb = beta_smb, lambda_hml = beta_hml)

# 3. Final Statistics (Step 3 Inference)
final_stats <- fmb_lambdas |>
  summarise(
    # Average Risk Premia
    mean_lambda_0   = mean(lambda_0),
    mean_lambda_mkt = mean(lambda_mkt),
    mean_lambda_smb = mean(lambda_smb),
    mean_lambda_hml = mean(lambda_hml),
    
    # Fama-MacBeth t-statistics (Mean / Standard Error)
    t_lambda_0   = mean(lambda_0) / (sd(lambda_0) / sqrt(n())),
    t_lambda_mkt = mean(lambda_mkt) / (sd(lambda_mkt) / sqrt(n())),
    t_lambda_smb = mean(lambda_smb) / (sd(lambda_smb) / sqrt(n())),
    t_lambda_hml = mean(lambda_hml) / (sd(lambda_hml) / sqrt(n()))
  ) |>
  pivot_longer(everything(), names_to = "stat", values_to = "value")

# Display nicely formatted table
knitr::kable(final_stats, digits = 4, caption = "Fama-MacBeth Risk Premia Estimates (Full Sample)")
```


The results indicate systematic pricing errors (significant intercept). MKT and SMB factors show positive expected risk premia, while HML is often insignificant or negative in the large-cap universe during this period.

### 3.3 Top Mispriced Stocks
We identify stocks with the largest pricing errors ($\alpha_i$). These are often growth or distressed firms where the factor model fails to capture idiosyncratic characteristics.

```{r}
# Create Name Map for readability
name_map <- stock_returns %>%
  group_by(ticker) %>%
  arrange(desc(date)) %>%
  slice(1) %>%
  ungroup() %>%
  select(ticker, symbol, company)

# Extract Vector of Lambdas
lambda_vec <- final_stats %>% 
  filter(stat %in% c("mean_lambda_mkt", "mean_lambda_smb", "mean_lambda_hml")) %>%
  pull(value)

# Calculate Alpha per stock
pricing_errors_full <- stock_betas %>%
  inner_join(
    fmb_data %>% 
      group_by(ticker) %>% 
      summarise(mean_excess_ret = mean(excess_ret, na.rm=TRUE)),
    by = "ticker"
  ) %>%
  mutate(
    # Predicted Return = Beta * Lambda
    predicted_ret = beta_mkt * lambda_vec[1] + 
                    beta_smb * lambda_vec[2] + 
                    beta_hml * lambda_vec[3],
    # Pricing Error
    alpha_i = mean_excess_ret - predicted_ret
  ) %>%
  left_join(name_map, by = "ticker") %>%
  select(ticker, symbol, company, alpha_i, beta_mkt, beta_smb, beta_hml) %>%
  arrange(desc(abs(alpha_i)))

knitr::kable(head(pricing_errors_full, 10), digits=4, caption = "Top 10 Mispriced Stocks (Full Sample)")
```


# 4. Sub-Period Analysis

We analyze the stability of risk premia across three distinct regimes: Pre-Crisis (1995-2007), Post-Crisis (2008-2019), and Pandemic/Recent (2020-2024).

```{r}
# Function to run FMB for a specific sub-period
run_subperiod_fmb <- function(data_for_betas, start_date, end_date, label,
                              min_months_beta = 24, min_cs_n = 10) {
  
  df_sub <- data_for_betas %>%
    filter(date >= as.Date(start_date), date <= as.Date(end_date)) %>%
    drop_na(excess_ret, mkt_excess, smb, hml)
  
  # Step 1: Betas
  betas_sub <- df_sub %>%
    group_by(ticker) %>%
    filter(n() >= min_months_beta) %>%
    summarise(model = list(lm(excess_ret ~ mkt_excess + smb + hml)), .groups = "drop") %>%
    mutate(coefs = map(model, tidy)) %>%
    unnest(coefs) %>%
    select(ticker, term, estimate) %>%
    pivot_wider(names_from = term, values_from = estimate) %>%
    rename(beta_mkt = mkt_excess, beta_smb = smb, beta_hml = hml)
  
  # Step 2: Lambdas
  fmb_lambdas_sub <- df_sub %>%
    inner_join(betas_sub, by = "ticker") %>%
    group_by(date) %>%
    filter(n() > min_cs_n) %>%
    summarise(model = list(lm(excess_ret ~ beta_mkt + beta_smb + beta_hml)), .groups = "drop") %>%
    mutate(coefs = map(model, tidy)) %>%
    unnest(coefs) %>%
    select(date, term, estimate) %>%
    pivot_wider(names_from = term, values_from = estimate) %>%
    rename(lambda_mkt = beta_mkt, lambda_smb = beta_smb, lambda_hml = beta_hml)
  
  # Step 3: Stats
  fmb_lambdas_sub %>%
    summarise(
      period = label,
      mean_mkt = mean(lambda_mkt, na.rm=T), 
      t_mkt = mean(lambda_mkt, na.rm=T)/(sd(lambda_mkt, na.rm=T)/sqrt(n())),
      mean_smb = mean(lambda_smb, na.rm=T), 
      t_smb = mean(lambda_smb, na.rm=T)/(sd(lambda_smb, na.rm=T)/sqrt(n())),
      mean_hml = mean(lambda_hml, na.rm=T), 
      t_hml = mean(lambda_hml, na.rm=T)/(sd(lambda_hml, na.rm=T)/sqrt(n()))
    )
}

# Run the three regimes
res1 <- run_subperiod_fmb(data_for_betas, "1995-01-01", "2007-12-31", "1995-2007")
res2 <- run_subperiod_fmb(data_for_betas, "2008-01-01", "2019-12-31", "2008-2019")
res3 <- run_subperiod_fmb(data_for_betas, "2020-01-01", "2024-12-31", "2020-2024")

knitr::kable(bind_rows(res1, res2, res3), digits=3, caption = "Sub-Period Risk Premia Analysis")
```


**Observation:** The estimated market risk premium weakens after 2008 and becomes statistically significant again only in 2020–2024. The consistently significant intercept suggests the FF3 model leaves a non-trivial average component unexplained in this large-cap universe, and factor premia appear regime-dependent.

# 5. Economic Significance

To test the economic validity of the model, we implement a **Real-Time Trading Strategy** free of look-ahead bias.

1.  **Rolling Betas ($\beta_{i,t}$):** Estimated using a 60-month trailing window (past information only).
2.  **Expanding Mean Lambdas ($\bar{\lambda}_t$):** Average of realized premia from the start of the sample up to time $t$.
3.  **Signal:** We forecast expected excess returns:
    $$\hat{E}_t[R_{i,t+1}^e] = \hat{\beta}_{i,t}^\top \bar{\lambda}_t$$

We sort stocks into Quintiles based on this signal and go **Long Q5 (High Exp. Return)** and **Short Q1 (Low Exp. Return)**.

```{r}
library(slider)

# Parameters
beta_window   <- 60   
min_beta_obs  <- 48   

# Filter valid data
df <- data_for_betas %>%
  arrange(ticker, date) %>%
  filter(is.finite(excess_ret), is.finite(mkt_excess), is.finite(smb), is.finite(hml))

# 1. Rolling Beta Estimation Function (Optimized)
rolling_betas_one_ticker <- function(d, window = 60, min_obs = 48) {
  fit_window <- function(win) {
    if (nrow(win) < min_obs) return(c(beta_mkt=NA, beta_smb=NA, beta_hml=NA))
    y <- win$excess_ret
    X <- cbind(1, win$mkt_excess, win$smb, win$hml)
    # Check for singularity
    if (nrow(X) < 4) return(c(beta_mkt=NA, beta_smb=NA, beta_hml=NA))
    fit <- lm.fit(x = X, y = y)
    b <- fit$coefficients
    c(beta_mkt = b[2], beta_smb = b[3], beta_hml = b[4])
  }
  
  betas_mat <- slide(
    .x = seq_len(nrow(d)), 
    .f = ~ {
      idx_end <- .x
      idx_start <- max(1, idx_end - window + 1)
      fit_window(d[idx_start:idx_end, ])
    }, 
    .complete = FALSE
  )
  betas_df <- bind_rows(lapply(betas_mat, as_tibble_row))
  bind_cols(d %>% select(date), betas_df)
}

# 2. Calculate Rolling Betas
betas_rolling <- df %>%
  group_by(ticker) %>%
  filter(n() >= min_beta_obs) %>% 
  group_modify(~ rolling_betas_one_ticker(.x, window = beta_window, min_obs = min_beta_obs)) %>%
  ungroup()

df_b_clean <- df %>%
  left_join(betas_rolling, by = c("date", "ticker")) %>%
  select(date, ticker, excess_ret, mktcap, mkt_excess,
         beta_mkt = matches("^beta_mkt\\..+"),
         beta_smb = matches("^beta_smb\\..+"), 
         beta_hml = matches("^beta_hml\\..+")) %>%
  filter(is.finite(beta_mkt))

# 3. Expanding Mean Lambdas & Strategy Construction
# Estimate monthly lambdas using lagged betas
fmb_lambdas_nla <- df_b_clean %>%
  group_by(ticker) %>%
  mutate(beta_mkt_lag = lag(beta_mkt), beta_smb_lag = lag(beta_smb), beta_hml_lag = lag(beta_hml)) %>%
  ungroup() %>%
  group_by(date) %>%
  summarise(coefs = list(tryCatch(tidy(lm(excess_ret ~ beta_mkt_lag + beta_smb_lag + beta_hml_lag)), error=function(e) NULL)), .groups="drop") %>%
  filter(!sapply(coefs, is.null)) %>%
  unnest(coefs) %>%
  select(date, term, estimate) %>%
  pivot_wider(names_from = term, values_from = estimate) %>%
  rename(lambda_mkt = beta_mkt_lag, lambda_smb = beta_smb_lag, lambda_hml = beta_hml_lag)

# Expand mean
lambdas_expanding <- fmb_lambdas_nla %>%
  arrange(date) %>%
  mutate(
    mean_lambda_mkt = cummean(lambda_mkt),
    mean_lambda_smb = cummean(lambda_smb),
    mean_lambda_hml = cummean(lambda_hml)
  ) %>%
  select(date, mean_lambda_mkt, mean_lambda_smb, mean_lambda_hml)

# 4. Strategy: Forecast & Sort
portfolio_rets_nla <- df_b_clean %>%
  left_join(lambdas_expanding, by = "date") %>%
  group_by(ticker) %>%
  mutate(next_excess_ret = lead(excess_ret)) %>%
  ungroup() %>%
  filter(is.finite(mean_lambda_mkt), is.finite(next_excess_ret)) %>%
  mutate(exp_excess_hat = beta_mkt * mean_lambda_mkt + beta_smb * mean_lambda_smb + beta_hml * mean_lambda_hml) %>%
  group_by(date) %>%
  filter(n() >= 100) %>% 
  mutate(q = ntile(exp_excess_hat, 5)) %>% 
  summarise(
    vw_ret_q1 = weighted.mean(next_excess_ret[q == 1], mktcap[q == 1], na.rm = TRUE),
    vw_ret_q5 = weighted.mean(next_excess_ret[q == 5], mktcap[q == 5], na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(ret_date = date %m+% months(1), ls_ret = vw_ret_q5 - vw_ret_q1) %>%
  arrange(ret_date)

# 5. Wealth Plot
wealth_plot_data <- portfolio_rets_nla %>%
  mutate(
    Wealth_Q5 = 100 * cumprod(1 + vw_ret_q5),
    Wealth_Q1 = 100 * cumprod(1 + vw_ret_q1),
    Wealth_LS = 100 * cumprod(1 + ls_ret)
  ) %>%
  pivot_longer(cols = starts_with("Wealth"), names_to = "Strategy", values_to = "Wealth")

ggplot(wealth_plot_data, aes(x = ret_date, y = Wealth, color = Strategy)) +
  geom_line(linewidth = 1) +
  scale_y_log10(labels = comma) +
  scale_color_manual(values = c("Wealth_Q5" = "green", "Wealth_Q1" = "red", "Wealth_LS" = "blue")) +
  labs(title = "Real-Time Economic Significance", 
       subtitle = "Long High Exp. Return / Short Low Exp. Return", 
       y = "Cumulative Wealth (Log)") +
  theme_minimal()
```




## 5.1 Alpha Check vs. Compensation for Risk
We regress the Long-Short strategy returns against the Fama-French 3 Factors to check for "Alpha".


```{r}
# Regress Long-Short Strategy Returns against FF3 Factors
# We need to join the factors back to the portfolio return dates
alpha_check_model <- lm(ls_ret ~ mkt_excess + smb + hml, 
                        data = portfolio_rets_nla %>% 
                          left_join(ff_factors, by = c("ret_date" = "date")))

# Display results
knitr::kable(tidy(alpha_check_model), digits=4, caption = "Alpha Check: LS Strategy vs FF3 Factors")
```

**Conclusion:** The Alpha is statistically insignificant. However, the factor loadings are significant. This confirms that the strategy generates returns not by "magic" (alpha), but by systematically harvesting the risk premia associated with Size (SMB) and Value (HML), as predicted by the model.

# References
1. Campbell, J. Y., Lo, A. W., and MacKinlay, A. C. (1997). *The Econometrics of Financial Markets*. Princeton University Press.
2. Cochrane, J. (2005). *Asset Pricing*. Princeton University Press.
3. Fama, E. F. and MacBeth, J. D. (1973). "Risk, return, and equilibrium: Empirical tests". *Journal of Political Economy*.
4. Fama, E. F. and French, K. R. (1993). "Common risk factors in the returns on stocks and bonds". *Journal of Financial Economics*.